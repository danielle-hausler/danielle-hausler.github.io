

### Research projects

Some of the research projects I have done during graduate studies.

#### 1) Incorporating Active learning Methods with Contextualized Sentence Representations (May, 2020)

As part of NLP course final project and together with Uri Katz, we investigated the relation between contextual text representations (Average BERT and Sentence BERT) and the effectiveness of the active learning procedure. Our empirical staudy revealed a relation between the representation type and the AL performance, based on the representation ability to separate classes. 
![image](https://github.com/danielle-hausler/danielle-hausler.github.io/blob/main/images/mr_f1_SenB.png?raw=True)
<br> More details can be found in the project's [paper](https://github.com/danielle-hausler/Incorporating_Active_learning_Methods_with_Contextualized_Sentence_Representations.pdf) and [code](https://github.com/daniellehausler/nlp_active_learning).


#### 2) Besov Smoothness Analysis of deep learning network layers with diffrent input (word) representations (September, 2019)

The final project of mathematical foundations to ML, together with Uri Katz we evaluated the "clusterability" of deep learning classifier layers using different representations (fasttext, word2vec, one-hot).
We measured the "clusterability" by a machinery of ‘weak-type’ Besov smoothness index that quantifies the geometry of the clustering in the feature space [(Elisha & Dekel, 2017)](https://arxiv.org/abs/1710.03263). We showed that the Besov smoothness index increased from layer to layer and that more informative representations resulted in higher smoothness index values for the last lyaers. 
![image, size=(10,8)](https://github.com/danielle-hausler/danielle-hausler.github.io/blob/main/images/besov_smoothness.png?raw=True)
<br> Further details can be found in the project's [presentation](https://github.com/danielle-hausler/danielle-hausler.github.io/blob/main/function%20space%20analysis%20of%20NLP%20models.pdf) and [code](https://github.com/katzurik/NLP_besov_smoothness).


  
